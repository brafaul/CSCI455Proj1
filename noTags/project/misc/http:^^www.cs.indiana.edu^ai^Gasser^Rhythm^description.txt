Date: Wed, 20 Nov 1996 19:16:35 GMT
Server: Apache/1.0.3
Content-type: text/html
Content-length: 2585
Last-modified: Mon, 08 Jul 1996 15:14:23 GMT


 Rhythm in Music and Speech

 Rhythm in Music and Language 
Description: 


Music and spoken language appear to be organized around hierarchically
structured patterns of strong and weak accents - that is, they have
rhythm.  People are expert at recognizing the rhythmic structure
in music and speech and guiding their own musical and linguistic behavior
to match (that is, be entrained to) a perceived rhythm.  Yet this capacity
is not well understood, and no computer program even approaches it.  Our
project is concerned (1) with experimental investigation of the perception
and production of rhythm in people and (2) with the development of a
computational model of the learning and processing of simple rhythmic
patterns.  The evolving model is based on the idea that periodicities in
the world must be captured by periodicities in the activity of the
computational device which is responsible for dealing with it.


In more general terms, this project is concerned with methods for
establishment of a `temporal lock' between a computational device and the
environment, that is, with entrainment between the realtime activity of a
computer and the world.  We suspect that such temporal locking is essential
for human-like speech and music behavior -- and probably many other
behaviors as well: catching a ball, dribbling a basketball, pushing a child
on a swing, and so forth.

 

 Associated Faculty: 
Robert Port,
Michael Gasser

 Associated Postdoc:   
Mauri Kaipainen (1996-7)

 Associated Graduate Students: 
Doug Eck,
Paul
Kienzle,
Fred
Cummins (Linguistics)

 Affiliated Projects: 
Accent Reduction Project:
Diane
Kewley-Port,
Robert Port

 Support:  
Office of Naval Research

 For more information 

click here 


  
Return to Computer Science Research Page
