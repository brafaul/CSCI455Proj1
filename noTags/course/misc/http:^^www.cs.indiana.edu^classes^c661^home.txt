Date: Wed, 20 Nov 1996 22:29:01 GMT
Server: Apache/1.0.3
Content-type: text/html
Content-length: 12535
Last-modified: Thu, 11 Apr 1996 04:38:16 GMT



 
C661: Natural Language Processing




C661: Natural Language Processing

Instructor: Mike Gasser
[Make an
appointment with me.]
[Send me a message.]
Time: TuTh 1:00-2:15
Room: Woodburn 114




Contents


Announcements

Topics

Coursework

Other sources of information

Schedule




Announcements


 Here is the final exam.
 A (fairly primitive) program for playing with Holographic
Reduced Representations (Plate) is at ~gasser/Apps/hrr on the
sharkestra, moose, and department SGIs.
Here is enough information to get you started
with it.
Here
is a new (optional) paper by Paul Rodriguez on
context-free languages and simple recurrent nets.






Topics

This course provides an introduction to the field of natural language
processing (or computational linguistics), including both analysis and
generation.  
Speech processing, machine translation, and computational
approaches to language acquisition and language evolution
are also given some attention.
A wide range of linguistic
phenomena, including phonology, morphology, syntax and semantics, and
pragmatics, will be treated,
and examples will come from various languages.
We will be concerned both with how well particular approaches solve
practical problems and with how well they model human data.

The course is divided into two relatively separate components.
The first deals with symbolic approaches to language
processing.
We will cover parsing and generation algorithms, emphasizing
modern unification-based approaches, but will spend
more of our time considering the sorts of grammars that support
parsing and generation.
With respect to theory and notation, we will stick mainly with
Head-Driven
Phrase Structure Grammar,
probably the most popular approach in computational
linguistics today.

The second component of the course
deals with statistical and connectionist approaches to language
processing, which, despite their very different
origins and motivation, share many underlying mechanisms as well as a
lack of built-in linguistic knowledge.
We will emphasize the acquisition of knowledge (phonological,
morphological, syntactic, semantic),
temporal processing, and
the relation between perception and the grammar/lexicon.

The course schedule, however, will be organized around topics rather
than approaches.
Thus we will look at morphology, approaches to parsing, and semantic
case, for example, in each case considering how both symbolic and
connectionist/statistical approaches deal with the problem.
For each topic we will also look at acquisition as well as processing.






Coursework and Prerequisites


Students should have some background in AI (such as
C563-564) and be
able to program in Scheme or Lisp.  Some linguistics background would
also be very helpful but is not required.
Cognitive science students from outside of computer science are
encouraged to enroll.

Coursework includes

Project (50%)
This may be done in collaboration with others in the class.
It should include a running program, though this can be based on
existing software in the case of connectionist models,
and a report which relates the work to other work in the area.
An attempt will be made to relate projects to each other by
constraining the type of language that is handled. 

Grading: paper (25%); relevance (25%); originality, success, lessons learned
(50%)


Suggestions for projects

A simple story you might want to use
for your project

Exams (40%)
There will be two exams, each covering half of the course.
You need only take the portion of each exam covering the approach
(symbolic or connectionist/statistical) which is not related to your
project.

Discussion of papers (10%)
Students will be responsible for leading discussion of some of the
papers we will be reading.
Here's a schedule.


Readings for the class will be kept on reserve in Swain Library.  A
copy will also be left in a box in the Computer Science Department
Copy Room.

Reading list


Discussants for readings





Class Newsgroup






Some Other Sources of Information


The Computational
Linguistics E-Print Archive
ACL Home Page
The
Natural Language Software Registry
Information
on Igor Mel'chuk
Tutorial
on One Approach to NL Generation
Tutorial
on Speech Visualization
Index to
various speech-related sites
PC Kimmo and Related
Programs
The
Language Software Helpdesk






Schedule


Week 1: Introduction

Tu
The "field"
Questioning everything sacred
Th
The big picture
Dimensions along which approaches vary
Kinds of linguistic knowledge
Overview of connectionist models

Week 2: Words -- Phonology, Morphology: A Symbolic Approach

Readings: Gazdar and Mellish, ch. 2; Antworth
Tu
Phonology and morphology: linguistic introduction
Two-level phonology/morphology (updated 9/12)

Week 3: Words -- Phonology, Morphology: Connectionist Approaches

Readings: Gasser, Regier
Tu
Two-level phonology/morphology: recognition
Acquisition of morphology
Th
Project ideas
Reduplication: A challenge to morphology models

Week 4: Words -- Lexical Semantics: Symbolic and Connectionist
Approaches

Tu
Lexical semantics
Mel'chuk's
approach to lexical relations (Ari)
Tour of LETRS (Main Library)

Week 5: Words -- Lexical Semantics: Statistical Approaches; Speech

Readings: Schütze, Allen (Appendix C)
Tu
Grounding word meaning
Schütze
(Doug)

Word-sense disambiguation
Th
Speech

Week 6: Phrases and Sentences -- Context-Free Grammars, Augmented
Grammars

Reading: Gazdar and Mellish, ch. 4
Tu
Syntax and semantics 1
Th
Grammars 1

Week 7: Phrases and Sentences -- Syntax and Semantics, Compositionality

Tu
Grammars 2
More problems
with simple context-free grammars (Yes, this is an old slide from C564.)
Introduction to information-based grammars
Th
What HPSG grammars look like (1)

Week 8: Phrases and Sentences -- Unification Grammars

Tu
What HPSG grammars look like (2)
Th
Unification revisited
Parsing 1

Week 9: Phrases and Sentences -- Connectionist Syntax and Semantics

Readings: Pollack, Elman
Tu
Another HPSG example
The problem of structure in connectionist nets
Th
Connectionist approaches to structure
Pollack (Jeff)

Week 10: Phrases and Sentences: Connectionist Structure (cont.),
Parsing

Tu
Elman (Andy)
More on connectionist structure
Th
Some parsing issues

Week 11: Phrases and Sentences -- Parsing and Generation;
Spreading-Activation Approaches

Readings: Lange and Wharton
Tu
Chart parsing
Ambiguity
Th
Some approaches to sentence
generation
Lange and Wharton (Jim)

Week 12: Machine Translation, Statistical Approaches Again,
Discourses -- Symbolic Approaches

Readings: Hutchins and Somers, Allen (ch. 7)
Tu
Localist connectionist networks
Statistical approaches to syntax
Th
Machine translation: Hutchins and Somers (Michael)

Week 13: Discourses -- Symbolic Approaches

Tu
Machine translation (cont.)
Pragmatics (overview)
Speech
acts 1
Speech acts 2

Week 14: Discourses -- Symbolic and Connectionist Approaches

Reading: St. John
Tu
Progress report on project due 
St. John (Wendy)
Using world knowledge
Th
Discourse structure 
Mélange of last-minute topics: metaphor, metonymy, humor, 
deception (none of which I have a good account of)

Week 15: Language Acquisition Revisited

Tu
Comparison and analogy; mental spaces
Th
Language acquisition
Parting thoughts
Final exam

Week 16

Mo (23:59:59)
Exams due (electronically)
Tu (5:00-7:00pm)
Reports on projects
Project reports due











Last updated: 17 December 1995
URL: http://www.cs.indiana.edu/classes/c661/home.html
Comments: 
gasser@salsa.indiana.edu
Copyright 1995,
The Trustees of
Indiana University





