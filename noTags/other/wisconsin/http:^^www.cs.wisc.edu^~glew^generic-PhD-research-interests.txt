Date: Tue, 05 Nov 1996 21:15:18 GMT
Server: NCSA/1.5
Content-type: text/html
Last-modified: Thu, 12 Sep 1996 23:37:54 GMT
Content-length: 16868





	Andy Glew - Statement of Purpose: Ph.D. Application, 1995
	


Andy Glew: Statement of Purpose
(0) What this document is

	    This document is my Statement of Purpose.
	    It is being prepared as part of my application
	    for admission to Ph.D. studies in 
	    Computer Architecture
	    (Electrical/Computer Engineering).

	(1) Introduction

	    My "goals for graduate study and a professional career"
	    can be briefly described as to do leading edge research in
	    high performance, low cost computing design.

	     In section (3) below I discuss these goals in more
	    detail, and also talk about my career options as a computer
	    architect in industry, and as a researcher in industry and
	    academia.

	     In section (4) I discuss my research interests: in
	    section (4.1) at a very high level indicating the true
	    breadth of my interests, but in section (4.2) at a very
	    specific level that I propose for my Ph.D. research.

	     I am almost embarrassed to admit to the degree of
	    abstraction and the theoretical nature of some of the
	    things I discuss in section (4.1).  I mention them mainly
	    to show that I am not a boring drone with a one-track
	    mind, incapable of understanding or contributing to fields
	    other than the one in which I am specializing.

	     In section (4.2) I propose a particular plan of
	    research.  I have great hope that it will be productive.

	     However, since it is necessary to balance the
	    abstract ideas of my research interests with the
	    practical details of graduate school and my
	    professional career, in section (2) I provide a brief
	    autobiographical sketch, in the hope that this background
	    may help explain why I wish to achieve some of the things
	    I am setting out to do, and give credence to my likelihood
	    of achieving them.

	(2) Autobiographical Sketch

	    I graduated from McGill University with a B.Eng. in
	    Electrical Engineering in 1985.  Between 1985 and 1989, I
	    worked as a programmer at a computer graphics company
	    (Formic) and in an operating systems development group
	    (Gould), and as a performance analysis in a company that
	    manufactured computers (Motorola).
	    
	     I completed my M.S. at the University of Illinois,
	    under Professor Wen-Mei Hwu, in 1991.  Although my
	    Master's Thesis was on a topic in multiprocessor cache
	    protocols, the bulk of my research was in out-of-order,
	    speculative, CPU microarchitectures.

	     Starting work at Intel in 1991, I got the chance to
	    apply my CPU microarchitecture research, which I had
	    actually begun while an undergraduate at McGill, and
	    carried through the University of Illinois. I was one of
	    the five principal architects of the P6 (now called
	    Pentium Pro) microprocessor. P6 is one of the first, and
	    still most aggressive, out-of-order, speculative
	    microprocessors.

	     Now that the P6 processor project is completed, I have
	    decided to complete the Ph.D. research which I suspended
	    five years ago.  I am also entering a new role at Intel,
	    as the first member of the Microcomputer Research Labs'
	    Intel Architecture group.  Although competing my
	    Ph.D. necessarily takes priority, I hope to perform a
	    balancing act between academic research and industrial
	    research.
	    

	(3) Goals for Graduate Study and a Professional Career
	    
	    My goals for graduate school are as follows: I have a
	    specific area in mind, research into advanced CPU
	    microarchitectures.  I hope that my Ph.D. research will be
	    as relevant as my earlier work, and that the designs I
	    will investigate will be practical enough to influence the
	    design of computers in industry at the completion of my
	    Ph.D.  I.e. I hope that my research will influence the
	    design of computers shipping in the years 2005-2015. But I
	    am open to other topics as described in my interests
	    section, section (4.1), below.

	    It should be obvious from my autobiographical sketch,
	    section (2), that I am already well established in my
	    professional career.  I have occasionally been accused of
	    being overly theoretical or academic in my analyses of
	    problems in computer design, so I have been sensitive to
	    the dictum
		"Those who can, do. Those who can't teach (or do
	    research)" but I think that my successful role in P6
	    disproves this.

	    Long term, I wish to continue to do leading edge work
	    in computer design: initially in industry, but also
	    perhaps in an academic setting.  If I stay with Intel my
	    career goal is to become an Intel Fellow, with technical
	    seniority sufficient to influence the direction of the
	    corporation.  I do not, however, have plans to become
	    exclusively a manager.  On the other hand, I am
	    considering returning to a university to teach and do
	    research, perhaps in my native country, Canada, always
	    with the hope of keeping my industrial contacts to
	    increase the chances of performing relevant research.

	(4) Research Interests

	    In section (4.2) I describe one particular area in which I
	    am interested in doing research. Before this, though, in section
	    (4.1) I describe some very broad areas that are of
	    interest to me. But, again, before this, I describe my 
	    motivation most succinctly in section (4.0).

	     It can be seen that, although I have chosen a
	    particular, very practical, area of applied and
	    experimental research in computer architecture, my
	    interests are more general.

	    (4.0) Motivation

I want to make computers faster.
		I want to make computers faster, 
		    to relieve humans of intellectual drudgery.
		I want to make inexpensive computers faster,
		    fast enough to support natural modes of interaction with users.
		    
I want to make inexpensive computers fast enough
			so that non-computer literate people like my parents
			can use them.
		    
I want to make computers faster,
		    fast enough that "artificial intelligence"
		    can reasonably be studied without the constraints
		    of insufficient computing resources.
		I think that the study of computers
		    produces insights into both intelligence
		    and the structures of mathematical and logical systems;
		    for the moment, my contribution is to make computers faster,
		    but I am eventually interested in working in these
		    other areas of knowledge.
		
(4.1) Broad, High Level

		Overall, I am interested in the augmentation of human
		intelligence using computers.  I am interested enough
		that, did I not already have a topic in mind, I would
		consider doing applied research developing software
		such as "thinking tools", agents, and improved ways of
		representing human knowledge such as the as-yet
		unachieved ideal of Vannevar Bush's MEMEX hypertext
		system.

		 It became obvious to me when I first
		encountered such issues that the user interface was a
		major obstacle to truly creating tools that augment
		human intelligence. Hence my interest in 3D graphics,
		virtual reality, and speech and handwriting
		recognition.

		 In the mid-1980s, when I started my career, it was
		obvious that one of the greatest obstacles to
		such improved user interfaces and thinking tools was
		lack of computational power.  Therefore, I have spent
		most of my career, to date, improving computer systems
		performance, so that one day the user interfaces that
		I wish to use will be cheap and ubiquitous.

		 Similarly, the fact that most computer systems do not
		provide real-time responsiveness, even when 
		computationally capable of it, is an obstacle to human 
		interaction with computers. Hence my involvement in real-time 
		operating systems design when I was a software developer,
		and my provision of the hardware prerequisites for providing
		"real-timeliness" as a hardware developer.  
		I remain interested in the incorporation of time as a criterion
		in most computer systems, primarily software, design:
		not-so-much in the sense of hard real time, 
		but in the sense of "compile this program, giving me the
		best code you can produce in half an hour".

		 Although my chief focus has been in
		computer design, I have remained somewhat involved in
		the first two areas of research, by investigating
		computer enhancements to increase performance in these
		areas specifically, and also through my involvement in
		Intel's "Natural Datatypes Technical Committee".
     
		 In case these interests are insufficiently
		abstruse, I also admit to a continued interest in: (1)
		sociology and economics, specifically market
		imperfections, which seem to me to be closely related
		to issues such as the cost of computation; and also
		(2) the theory of imperfect, or incomplete, systems,
		both logical and algorithmic.

		 However, in order to make progress in life, one
		must focus; and I propose to focus on the areas
		described in section (4.2).

	    (4.2) Specific Research Focus

		The area that I propose to do research in, which has
		been the primary focus of my last ten years, is
		increasing the performance of computers to facilitate
		the applications, both "thinking" and "user
		interface", I describe above.  Specifically, my
		interest is in increasing the computing power
		available to the average member of our society.
		
		 Although I have worked for supercomputer
		manufacturer, in my research capacity I am not
		concerned with techniques that are applicable only to
		supercomputers.  Although many supercomputer
		techniques are relevant to the mass market
		microprocessors that most of us use, many are not. In
		fact, at the moment, mass market microprocessor design
		is investigating many techniques that the old
		supercomputer manufacturers never considered.

		 More specifically, I propose to do research in
		uniprocessor, single CPU performance.  This is not
		because I think that research in multiprocessors is
		inappropriate; just that I think that there is a lot
		of headroom for improvement in single CPU
		performance. 
		Furthermore, as may become obvious in the more
		detailed explanation of my research interests, the
		style of CPU microarchitecture which I propose to
		investigate may also serve as a bridge between
		uniprocessor and multiprocessor CPU design.

		 The basic problem in modern computer design is
		that the speed of the CPU is increasing faster than
		the speed of memory. Also, the economics of the memory
		(DRAM) market tend to prohibit the parallel,
		interleaved, memory subsystem techniques that have
		been used on traditional supercomputers to increase
		performance. Although such techniques will eventually
		be applied, the gap between CPU and memory performance
		is growing.

		 My basic approach is to investigate extremely
		aggressive, advanced, CPU microarchitectures,
		extending out-of-order, speculative, and dynamic
		execution far beyond what we are currently
		implementing. The hope is that, by creating as large a
		pool as possible of memory references, that we can use
		the existing limited memory bandwidth in as efficient
		a manner possible. The techniques that I currently
		have in mind include:

		
 Microarchitecture 

			The following list of techniques starts
			with the most aggressive,
			ending with techniques that are only a little 
			bit beyond the present state of the art in industry.
			


 Skip ahead 
 Modern CPUs execute instructions in parallel
				and out-of-order, but they continue to fetch
				instructions in a largely sequential manner.  Rather
				than "looking ahead" in the sequential instruction
				stream, I propose to "skip ahead", and fetch
				discontiguous instruction packets.  For example, I
				propose microarchitectures that can determine when
				subsequent procedures are independent of each other, and
				which will fetch and execute those procedures in
				parallel. 
 Related research includes the general topic of
				"multithreading", as advocated by Tera Computers, and
				also the "multiscalar" research being carried out by
				Guri Sohi at Wisconsin.  However, while these other
				researchers posit an explicitly parallel instruction set
				(which I will also consider, see below), I am optimistic
				that these techniques can be applied equally well to
				existing instruction sets, seeking parallelism implicit
				in an existing "single-threaded" program. 
 I.e., rather than the micro-scale parallelism of present
				CPU designs, or the macro-scale parallelism of true
				multiprocessors, I propose to investigate meso-scale
				parallelism. I have some hope that such designs might allow
				a more gradual evolution into true multiprocessing, hence
				overcoming the market barriers that have hindered
				multiprocessing in real life. 
 I therefore envisage computer systems in which
				micro-scale parallelism is taken advantage of by
				"dynamic execution" techniques such as I and my
				coworkers employed in the P6 (Pentium Pro) processor;
				meso-scale parallelism is taken advantage of by
				skip-ahead mechanisms as I describe above; and
				macro-scale parallelism is taken advantage of by
				explicit multiprocessors. 
 Convergent Code 
 Also known as "Minimal Control Dependencies", from
				Tjaden and Flynn's seminal paper in the 1970s, this is
				based on the observation that much of the time, in a modern
				processor with speculative branch execution, work after the
				close of the "ENDIF" part of an "IF" is independent of the
				path through through the "IF". The goal is to avoid
				needlessly throwing useful work away. 
 Incremental and Selective Speculation Recovery 
 In fact, the theme of avoiding needlessly throwing
				correct work away can be extended to forms of speculation
				other than branch prediction, such as data speculation.  A
				joyful synergy is found because the general mechanism for
				solving this problem also seems to solve the problems of
				convergent code and skip-ahead processing.  
 Eager Execution 
 Finally, I will consider Eager Execution - executing
				both sides of a branch. However, since this is something
				that is already on the verge of being implemented in
				industry, and since research to date shows that its benefits
				are mixed (introducing extra memory traffic due to executing
				unneeded paths is undesirable on the memory starved
				processor model I have in mind), I consider that Eager
				Execution is ancillary to the techniques I already
				mention. However, the same mechanisms that support the
				previous techniques also support Eager Execution, so it
				would be foolish not to investigate it. 


 Instruction Set Design 
 Finally, some of my betters at Intel are encouraging me to
			investigate possible new ISA paradigms better matched to modern
			microarchitecture.  Just as RISC instruction sets were well
			matched to the simple pipelined processors of the early 1980s,
			and VLIWs are well matched to the processor designs of the early
			1990s, so it is possible that a new style of instruction set may
			be better matched to the out-of-order, speculative, processor
			designs of the present, or perhaps to the memory starved
			processors of the future. 
I always keep the possibility of new instruction set
			principles at the back of my mind, but I also take care to
			resist succumbing to temptation too easily.  I have often found,
			however, that designing new instruction set features is a
			useful technique, since once new features have been designed you
			have only to devise an equivalent way of implicitly predicting
			or performing the same function in hardware, without the new
			instruction set features. 


(6) Conclusion
	
	    In conclusion, therefore, my interests are broad,
	    but I plan to focus on a single area,
	    applied, experimental, research in computer architecture,
	    I believe this area to be both relevant to industry,
	    but also challenging enough to warrant a Ph.D.
			

	

	$Header: /u/g/l/glew/public/html/RCS/generic-PhD-research-interests.html,v 1.1 1996/09/12 23:37:44 glew Exp $


    

